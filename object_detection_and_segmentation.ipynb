{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "\n",
    "Object detection is a computer technology related to computer vision and image processing that deals with detecting instances of semantic objects of a certain class (such as humans, buildings, or cars) in digital images and videos. Well-researched domains of object detection include face detection and pedestrian detection. Object detection has applications in many areas of computer vision, including image retrieval and video surveillance. [(Source: Wikipedia)](https://en.wikipedia.org/wiki/Object_detection)\n",
    "\n",
    "![head_image](images/obj1.jpg)\n",
    "\n",
    "## Basics of Object Detection\n",
    "\n",
    "### Image Classification using Convolutional Neural Networks (CNNs)\n",
    "\n",
    "In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery. They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on their shared-weights architecture and translation invariance characteristics. They have applications in image and video recognition, recommender systems, image classification, medical image analysis, natural language processing, and financial time series.\n",
    "\n",
    "Convolutional Neural Networks have gained a lot of popularity & attention in recent years. They have been employed in many supervised and unsupervised learning problems. Image Classification is the task where we CNN to classify images into different categories. Image Classifications using CNNs is the first step in Object Detection. Example: Train the CNN to classify images of dogs and cats.\n",
    "\n",
    "![cnn](images/cnn.gif)\n",
    "\n",
    "### Localization of object in the image\n",
    "\n",
    "Localization is the part of object detection where a specific object's location is detected in a given image. There are multiple approaches to detect the object in a given image. \n",
    "\n",
    "One may ask is the neural network supposed to detect the object in the image by it's own since it performs feature extraction and learns hidden features by its own. \n",
    "\n",
    "The answer is **No**. \n",
    "\n",
    "![ti](images/ti.gif)\n",
    "\n",
    "It is because of the primary architecture of the traditional CNN which only focuses on learning the features as they occur in an image and does not care about where it occurs. \n",
    "\n",
    "This problem is known as the **Translation Invariance**, where the neural network only cares about the occurence of features and not it's location.\n",
    "\n",
    "This means that we cannot perform localization to detect where an object occurs in an image.\n",
    "\n",
    "To overcome this issue, we have 2 commonly used approaches and let us have a look at them.\n",
    "\n",
    "#### 1. Sliding Window approach\n",
    "\n",
    "Imagine you move through the image using smaller windows like kernels in Convolutions. You basically move through the image in windows and apply the image classifier to see if it classifies any objects. \n",
    "\n",
    "![window](images/window.webp)\n",
    "\n",
    "This is performed again and again with different window sizes to get set of windows containing the classified objects present in the image. \n",
    "\n",
    "![boxes](images/boxes.webp)\n",
    "\n",
    "This is then visualized by drawing a bounding box for each window of objects. Extra windows can be eliminated by considering the confidence scores.\n",
    "\n",
    "![sliding_windows](images/sw.webp)\n",
    "\n",
    "This method has been used in many computer vision techniques like HAAR Cascades, HOG SVMs, etc. But this method is not efficent and is highly computationally expensive.\n",
    "\n",
    "#### 2. Using Object Coordinates approach\n",
    "\n",
    "If translation invariance is the problem in object detection using traditional CNNs, why not give the neural network the information about where the object occurs when training set of images so they can predict the object as well its location in any given image?\n",
    "\n",
    "Yes, it is 100% possible but how do we do that? The answer to this question is we have to annotate our images in the dataset by adding bounding boxes over the objects. Some of the tools that can be used for annotating images for object detection are [OpenLabeling](https://github.com/Cartucho/OpenLabeling), [LabelImg](https://github.com/tzutalin/labelImg), etc.\n",
    "\n",
    "![label](images/labelling.jpg)\n",
    "\n",
    "Once you annotate your images you'll have to train your CNN model with the coordinates using Regression apart from the image classification. You can use any frameworks for this purpose such as Tensorflow Object Detection API, YOLO, Keras, Pytorch/TorchVision, etc."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}